# Quy TrÃ¬nh DevSecOps & GitOps - NT114 Project

**Version:** 1.0
**Updated:** January 4, 2026
**Status:** âœ… Production Ready

---

## ğŸ“‹ Tá»•ng Quan

Project NT114 DevSecOps sá»­ dá»¥ng quy trÃ¬nh **tá»± Ä‘á»™ng hoÃ n toÃ n** tá»« code â†’ build â†’ deploy â†’ monitor trÃªn **Ä‘a mÃ´i trÆ°á»ng** (dev/prod) vá»›i cÃ¡c cÃ´ng nghá»‡:

- **Infrastructure as Code (IaC)**: Terraform quáº£n lÃ½ toÃ n bá»™ AWS infrastructure
- **GitOps**: ArgoCD tá»± Ä‘á»™ng sync vÃ  deploy applications tá»« Git
- **CI/CD**: GitHub Actions xÃ¢y dá»±ng vÃ  Ä‘áº©y container images
- **Container Registry**: AWS ECR lÆ°u trá»¯ Docker images
- **Orchestration**: Amazon EKS (Kubernetes) cháº¡y workloads
- **Monitoring**: Prometheus + Grafana + CloudWatch
- **Security**: Security scanning, RBAC, network policies

---

## ğŸ”„ Quy TrÃ¬nh HoÃ n Chá»‰nh (End-to-End Flow)

### BÆ°á»›c 1: Developer Push Code

```
Developer
  â”‚
  â”œâ”€ git add .
  â”œâ”€ git commit -m "feat: add new feature"
  â””â”€ git push origin main
      â”‚
      â””â”€â”€> Trigger GitHub Actions Workflow
```

**Äiá»u kiá»‡n trigger:**
- Push/PR Ä‘áº¿n branch `main`
- Thay Ä‘á»•i trong: `microservices/**`, `frontend/**`, `helm/**`
- File: `.github/workflows/deploy-dev.yml`

---

### BÆ°á»›c 2: GitHub Actions CI/CD Pipeline

**Workflow:** `.github/workflows/deploy-dev.yml`

#### 2.1. Detect Changes
```yaml
detect-changes:
  - PhÃ¡t hiá»‡n service nÃ o thay Ä‘á»•i (frontend, backend microservices)
  - Output: backend=true/false, frontend=true/false
  - DÃ¹ng git diff Ä‘á»ƒ so sÃ¡nh vá»›i commit trÆ°á»›c
```

#### 2.2. Build & Push Images (Song Song)

**Frontend Build:**
```yaml
build-frontend:
  if: needs.detect-changes.outputs.frontend == 'true'
  steps:
    1. Checkout code
    2. Login AWS ECR
    3. Build Docker image:
       - File: frontend/Dockerfile.prod
       - Base: nginx:alpine
       - Build React app (Vite)
       - Tag: <commit-sha>
    4. Scan image vá»›i Trivy (security scan)
    5. Push Ä‘áº¿n ECR:
       - Repository: nt114-devsecops/frontend
       - Tags: latest, <commit-sha>
```

**Backend Services Build (4 services parallel):**
```yaml
build-backend:
  matrix:
    service:
      - api-gateway
      - user-management-service
      - exercises-service
      - scores-service
  steps:
    1. Checkout code
    2. Login AWS ECR
    3. Build Docker image:
       - File: microservices/<service>/Dockerfile
       - Tag: <commit-sha>
    4. Scan image vá»›i Trivy
    5. Push Ä‘áº¿n ECR
```

**Output:** 5 Docker images Ä‘Ã£ Ä‘Æ°á»£c push vÃ o AWS ECR

---

#### 2.3. Update Helm Values (GitOps)

```yaml
update-helm-values:
  needs: [build-frontend, build-backend]
  steps:
    1. Update helm/*/values-dev.yaml:
       - Thay Ä‘á»•i image tag tá»« old-sha â†’ new-sha
    2. Commit changes:
       - Message: "chore(dev): update image tags to <sha> [skip ci]"
    3. Push vá» GitHub repo
       - Branch: main
```

**VÃ­ dá»¥ thay Ä‘á»•i:**
```yaml
# helm/frontend/values-dev.yaml
tag: "d8d567a5d9b8053586d9dd9b60287e521a41508b"  # â† Tá»± Ä‘á»™ng update
```

**Káº¿t quáº£:** Git repo cÃ³ commit má»›i vá»›i Helm values updated

---

### BÆ°á»›c 3: ArgoCD GitOps Sync

ArgoCD liÃªn tá»¥c **watch Git repository** (polling interval: 3 phÃºt)

#### 3.1. Detect Changes
```
ArgoCD Controller
  â”‚
  â”œâ”€ PhÃ¡t hiá»‡n Helm values thay Ä‘á»•i
  â”œâ”€ So sÃ¡nh desired state (Git) vs actual state (K8s)
  â””â”€ Táº¡o diff report
```

#### 3.2. Auto-Sync
```yaml
ArgoCD Application Config:
  syncPolicy:
    automated:
      prune: true      # XÃ³a resources khÃ´ng cÃ²n trong Git
      selfHeal: true   # Tá»± sá»­a náº¿u ai chá»‰nh trá»±c tiáº¿p K8s
    syncOptions:
      - CreateNamespace=true
```

#### 3.3. Deployment Process
```
ArgoCD
  â”‚
  â”œâ”€ 1. Render Helm charts vá»›i values má»›i
  â”œâ”€ 2. Generate Kubernetes manifests
  â”œâ”€ 3. Apply manifests Ä‘áº¿n EKS cluster
  â”‚   â”œâ”€ Create new ReplicaSet vá»›i image má»›i
  â”‚   â”œâ”€ Rolling update pods (zero-downtime)
  â”‚   â””â”€ Wait for health checks pass
  â””â”€ 4. Mark sync status: Synced âœ…
```

**Rolling Update Strategy:**
```yaml
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 1        # Táº¡o thÃªm 1 pod má»›i
    maxUnavailable: 0  # KhÃ´ng terminate pod cÅ© cho Ä‘áº¿n khi má»›i ready
```

**Health Checks:**
```yaml
readinessProbe:
  httpGet:
    path: /health
    port: 80
  initialDelaySeconds: 10
  periodSeconds: 5

livenessProbe:
  httpGet:
    path: /health
    port: 80
  initialDelaySeconds: 30
  periodSeconds: 10
```

---

### BÆ°á»›c 4: Kubernetes Deployment

**EKS Cluster Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           EKS Cluster: eks-1               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚  Node Groups (Spot Instances):            â”‚
â”‚  â”œâ”€ app: t3.medium (2 nodes, 4GB RAM)     â”‚
â”‚  â”œâ”€ argocd: t3.medium (1 node)            â”‚
â”‚  â””â”€ monitoring: t3.medium (1 node)        â”‚
â”‚                                            â”‚
â”‚  Namespaces:                               â”‚
â”‚  â”œâ”€ dev (applications)                     â”‚
â”‚  â”œâ”€ prod (applications)                    â”‚
â”‚  â”œâ”€ argocd (GitOps controller)            â”‚
â”‚  â””â”€ monitoring (Prometheus, Grafana)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pod Deployment:**
```
1. Pull image tá»« ECR:
   - ImagePullPolicy: Always
   - Credential: ecr-secret

2. Start containers:
   - Resource limits (CPU/Memory)
   - Environment variables
   - Volume mounts (náº¿u cáº§n)

3. Service exposure:
   - Frontend: LoadBalancer (public)
   - Backend: ClusterIP (internal)
   - ArgoCD: NodePort (kubectl port-forward)
   - Monitoring: NodePort

4. Ingress/LoadBalancer:
   - AWS ALB tá»± Ä‘á»™ng provision
   - SSL/TLS termination
   - Health check routes
```

---

### BÆ°á»›c 5: Monitoring & Observability

#### 5.1. Prometheus Metrics
```
Prometheus
  â”‚
  â”œâ”€ Scrape metrics tá»«:
  â”‚   â”œâ”€ Kubernetes API
  â”‚   â”œâ”€ Node exporters
  â”‚   â”œâ”€ Application /metrics endpoints
  â”‚   â””â”€ ArgoCD controller
  â”‚
  â””â”€ Store time-series data
```

**Metrics thu tháº­p:**
- Container CPU/Memory usage
- HTTP request rate, latency, errors
- Database connections
- ArgoCD sync status
- Pod restart counts

#### 5.2. Grafana Dashboards
```
Grafana
  â”‚
  â”œâ”€ Dashboards:
  â”‚   â”œâ”€ Kubernetes Cluster Overview
  â”‚   â”œâ”€ Application Performance
  â”‚   â”œâ”€ ArgoCD Application Health
  â”‚   â””â”€ Cost Monitoring
  â”‚
  â””â”€ Alerts â†’ Slack/Email
```

Access:
```bash
kubectl port-forward svc/monitoring-grafana -n monitoring 3000:80
# http://localhost:3000
# Username: admin
# Password: (láº¥y tá»« GitHub Actions output)
```

#### 5.3. CloudWatch Logs
```
EKS â†’ CloudWatch Logs
  â”‚
  â”œâ”€ Control plane logs
  â”œâ”€ Application logs (stdout/stderr)
  â”œâ”€ Audit logs
  â””â”€ Performance insights
```

---

## ğŸŒ Äa MÃ´i TrÆ°á»ng (Multi-Environment)

### Dev Environment

**Purpose:** Development, testing, rapid iteration

```yaml
Characteristics:
  - Branch: main
  - Namespace: dev
  - Instances: Spot (cost-optimized)
  - Replicas: 2 per service
  - Auto-scaling: Enabled (2-5 pods)
  - Database: RDS (t3.micro)
  - Domain: dev.codeland.example.com
```

**Helm Values:**
```yaml
# helm/frontend/values-dev.yaml
replicaCount: 2
image:
  repository: 039612870452.dkr.ecr.us-east-1.amazonaws.com/nt114-devsecops/frontend
  pullPolicy: Always
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 128Mi
```

---

### Prod Environment

**Purpose:** Production workloads, high availability

```yaml
Characteristics:
  - Branch: release/prod
  - Namespace: prod
  - Instances: On-Demand (reliability)
  - Replicas: 3 per service
  - Auto-scaling: Enabled (3-10 pods)
  - Database: RDS (t3.small, Multi-AZ)
  - Domain: codeland.example.com
```

**Helm Values:**
```yaml
# helm/frontend/values-prod.yaml
replicaCount: 3
image:
  repository: 039612870452.dkr.ecr.us-east-1.amazonaws.com/nt114-devsecops/frontend
  pullPolicy: Always
resources:
  limits:
    cpu: 1000m
    memory: 1Gi
  requests:
    cpu: 200m
    memory: 256Mi
```

---

### Environment Promotion

**Dev â†’ Prod Process:**
```bash
# 1. Test in dev environment
git push origin main
# â†’ Deploy to dev via ArgoCD

# 2. Verify in dev
kubectl get pods -n dev
curl https://dev.codeland.example.com/health

# 3. Tag release
git tag -a v1.2.3 -m "Release v1.2.3"
git push origin v1.2.3

# 4. Merge to prod branch
git checkout release/prod
git merge main
git push origin release/prod
# â†’ Deploy to prod via ArgoCD

# 5. Monitor rollout
kubectl rollout status deployment/frontend-prod -n prod
```

**Rollback náº¿u cÃ³ lá»—i:**
```bash
# ArgoCD tá»± Ä‘á»™ng rollback náº¿u health check fail
# Hoáº·c manual rollback:
argocd app rollback frontend-prod
```

---

## ğŸ” Security Implementation

### 1. Container Security

**Image Scanning (Trivy):**
```yaml
- name: Scan Docker image
  uses: aquasecurity/trivy-action@master
  with:
    image-ref: ${{ env.ECR_REGISTRY }}/${{ matrix.service }}:${{ github.sha }}
    severity: CRITICAL,HIGH
    exit-code: 1  # Fail build náº¿u cÃ³ critical vulnerabilities
```

**Non-root Containers:**
```dockerfile
# Dockerfile.prod
FROM nginx:alpine
RUN addgroup -g 1001 -S appuser && \
    adduser -u 1001 -S appuser -G appuser
USER appuser
```

---

### 2. Kubernetes RBAC

**Service Accounts:**
```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: frontend-sa
  namespace: dev
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: frontend-role
rules:
  - apiGroups: [""]
    resources: ["configmaps", "secrets"]
    verbs: ["get", "list"]
```

---

### 3. Network Policies

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-network-policy
spec:
  podSelector:
    matchLabels:
      tier: backend
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
      - podSelector:
          matchLabels:
            tier: frontend
      ports:
        - protocol: TCP
          port: 8080
```

---

### 4. Secrets Management

**AWS Secrets Manager + External Secrets:**
```yaml
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: db-credentials
spec:
  secretStoreRef:
    name: aws-secrets-manager
  target:
    name: postgres-secret
  data:
    - secretKey: password
      remoteRef:
        key: prod/postgres/password
```

---

## ğŸ“Š Infrastructure as Code (Terraform)

### Terraform Modules Structure

```
terraform/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ main.tf           # Root module
â”‚   â”‚   â”œâ”€â”€ variables.tf      # Input variables
â”‚   â”‚   â”œâ”€â”€ outputs.tf        # Outputs
â”‚   â”‚   â”œâ”€â”€ terraform.tfvars  # Environment-specific values
â”‚   â”‚   â””â”€â”€ providers.tf      # AWS, K8s, Helm providers
â”‚   â””â”€â”€ prod/
â”‚       â””â”€â”€ (same structure)
â”‚
â””â”€â”€ modules/
    â”œâ”€â”€ vpc/                  # VPC, Subnets, NAT Gateway
    â”œâ”€â”€ eks-cluster/          # EKS control plane
    â”œâ”€â”€ eks-nodegroup/        # Worker nodes
    â”œâ”€â”€ rds/                  # PostgreSQL database
    â”œâ”€â”€ ebs-csi-driver/       # EBS CSI for persistent volumes
    â””â”€â”€ storage-classes/      # K8s storage classes (gp3)
```

---

### Terraform Deployment Flow

**1. Infrastructure Provisioning:**
```bash
cd terraform/environments/dev

# Initialize
terraform init

# Plan
terraform plan -out=tfplan

# Apply
terraform apply tfplan
```

**2. Resources Created:**
```
AWS Resources:
â”œâ”€ VPC (10.0.0.0/16)
â”‚  â”œâ”€ Public Subnets (2 AZs)
â”‚  â”œâ”€ Private Subnets (2 AZs)
â”‚  â”œâ”€ NAT Gateways (2)
â”‚  â””â”€ Internet Gateway
â”‚
â”œâ”€ EKS Cluster
â”‚  â”œâ”€ Control Plane (Managed)
â”‚  â”œâ”€ Node Groups (App, ArgoCD, Monitoring)
â”‚  â””â”€ OIDC Provider (for IAM roles)
â”‚
â”œâ”€ RDS PostgreSQL
â”‚  â”œâ”€ Instance (t3.micro)
â”‚  â”œâ”€ Subnet Group
â”‚  â””â”€ Security Group
â”‚
â”œâ”€ ECR Repositories
â”‚  â”œâ”€ frontend
â”‚  â”œâ”€ api-gateway
â”‚  â”œâ”€ user-management-service
â”‚  â”œâ”€ exercises-service
â”‚  â””â”€ scores-service
â”‚
â””â”€ IAM Roles & Policies
   â”œâ”€ EKS Cluster Role
   â”œâ”€ Node Group Role
   â”œâ”€ EBS CSI Driver Role
   â””â”€ ArgoCD Role
```

**3. Kubernetes Resources (via Terraform):**
```hcl
# EBS CSI Driver
module "ebs_csi_driver" {
  source            = "../../modules/ebs-csi-driver"
  cluster_name      = module.eks_cluster.cluster_name
  oidc_provider     = module.eks_cluster.oidc_provider
  oidc_provider_arn = module.eks_cluster.oidc_provider_arn
}

# Storage Classes
module "storage_classes" {
  source               = "../../modules/storage-classes"
  ebs_csi_driver_ready = module.ebs_csi_driver.addon_arn
}
```

**4. State Management:**
```hcl
# Local state (dev environment)
# Production should use S3 backend:
terraform {
  backend "s3" {
    bucket = "nt114-terraform-state"
    key    = "prod/terraform.tfstate"
    region = "us-east-1"
    encrypt = true
    dynamodb_table = "terraform-locks"
  }
}
```

---

## ğŸš€ Complete Deployment Example

### Scenario: ThÃªm Feature Má»›i

**1. Developer Code:**
```bash
# Táº¡o branch má»›i
git checkout -b feature/add-leaderboard

# Code feature
vim frontend/src/pages/Leaderboard.tsx

# Commit
git add .
git commit -m "feat(frontend): add leaderboard page"
git push origin feature/add-leaderboard

# Táº¡o PR
gh pr create --title "Add Leaderboard" --body "New leaderboard feature"
```

**2. Code Review & Merge:**
```bash
# Review qua GitHub UI
# Approve & Merge to main
```

**3. Automatic CI/CD:**
```
GitHub Actions (3-5 phÃºt):
  â”œâ”€ 1. Detect changes: frontend=true
  â”œâ”€ 2. Build Docker image:
  â”‚     - Tag: abc123 (commit SHA)
  â”‚     - Size: ~50MB (nginx + static files)
  â”œâ”€ 3. Security scan: âœ… Pass
  â”œâ”€ 4. Push to ECR: âœ… Done
  â””â”€ 5. Update Helm values:
        - helm/frontend/values-dev.yaml
        - tag: "abc123"
        - Commit & push
```

**4. ArgoCD Sync (1-3 phÃºt):**
```
ArgoCD:
  â”œâ”€ 1. Detect Git change
  â”œâ”€ 2. Render Helm chart
  â”œâ”€ 3. Deploy to K8s:
  â”‚     - Create new pods vá»›i image abc123
  â”‚     - Rolling update (0 downtime)
  â”‚     - Health check pass
  â””â”€ 4. Status: Synced âœ… Healthy âœ…
```

**5. Verification:**
```bash
# Check pods
kubectl get pods -n dev | grep frontend
# frontend-dev-6447f96fb9-xxxxx   1/1   Running   0   30s
# frontend-dev-6447f96fb9-yyyyy   1/1   Running   0   15s

# Check ArgoCD
kubectl get application frontend-dev -n argocd
# NAME           SYNC STATUS   HEALTH STATUS
# frontend-dev   Synced        Healthy

# Test endpoint
curl https://dev.codeland.example.com/leaderboard
# { "data": [...] }
```

**Total Time:** 5-8 phÃºt tá»« push code â†’ deploy production âœ…

---

## ğŸ¯ Key Benefits

### 1. Tá»± Äá»™ng HoÃ n ToÃ n
- âœ… KhÃ´ng cáº§n cháº¡y kubectl/helm thá»§ cÃ´ng
- âœ… KhÃ´ng cáº§n login vÃ o servers
- âœ… Git lÃ  single source of truth

### 2. Reliability
- âœ… Rolling updates (zero downtime)
- âœ… Auto-rollback náº¿u health check fail
- âœ… Immutable infrastructure

### 3. Security
- âœ… Image scanning trÆ°á»›c khi deploy
- âœ… RBAC enforcement
- âœ… Network policies
- âœ… Secrets khÃ´ng commit vÃ o Git

### 4. Observability
- âœ… Centralized logging (CloudWatch)
- âœ… Metrics & alerting (Prometheus/Grafana)
- âœ… Distributed tracing
- âœ… Audit logs

### 5. Cost Optimization
- âœ… Spot instances (dev: tiáº¿t kiá»‡m 70%)
- âœ… Auto-scaling (scale to zero khi khÃ´ng dÃ¹ng)
- âœ… Resource limits enforcement
- âœ… Cost monitoring dashboards

---

## ğŸ“š TÃ i Liá»‡u LiÃªn Quan

- **System Architecture:** `docs/system-architecture.md`
- **Deployment Guide:** `docs/deployment-guide.md`
- **Terraform Manual Fixes:** `docs/terraform-manual-fixes.md`
- **Accessing Services:** `docs/accessing-nodeport-services.md`
- **Monitoring Setup:** `docs/monitoring-gitops-architecture.md`

---

## ğŸ”§ Troubleshooting

### Image Pull Errors
```bash
# Check ECR permissions
kubectl get secrets ecr-secret -n dev -o yaml

# Recreate ECR secret
aws ecr get-login-password --region us-east-1 | \
  kubectl create secret docker-registry ecr-secret \
  --docker-server=039612870452.dkr.ecr.us-east-1.amazonaws.com \
  --docker-username=AWS \
  --docker-password-file=/dev/stdin \
  -n dev --dry-run=client -o yaml | kubectl apply -f -
```

### ArgoCD Sync Stuck
```bash
# Force refresh
argocd app get frontend-dev --refresh

# Manual sync
argocd app sync frontend-dev

# Check logs
kubectl logs -n argocd -l app.kubernetes.io/name=argocd-application-controller
```

### Pod Crashes
```bash
# Check logs
kubectl logs -n dev <pod-name> --previous

# Check events
kubectl describe pod -n dev <pod-name>

# Check resource constraints
kubectl top pod -n dev <pod-name>
```

---

**Káº¿t luáº­n:** ToÃ n bá»™ quy trÃ¬nh tá»« code â†’ production hoÃ n toÃ n tá»± Ä‘á»™ng, an toÃ n, vÃ  cÃ³ thá»ƒ quan sÃ¡t Ä‘Æ°á»£c. Developer chá»‰ cáº§n `git push`, cÃ²n láº¡i há»‡ thá»‘ng tá»± Ä‘á»™ng xá»­ lÃ½! ğŸš€
